{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJd3dlOCStH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/main/ddsp/colab/tutorials/3_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "\n",
        "##### Copyright 2021 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VNhgka4UKNjf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFIqwYGbZ-df"
      },
      "source": [
        "# DDSP Training\n",
        "\n",
        "This notebook demonstrates the libraries in [https://github.com/magenta/ddsp/tree/master/ddsp/training](https://github.com/magenta/ddsp/tree/master/ddsp/training). It is a simple example, overfitting a single audio sample, for educational purposes. \n",
        "\n",
        "_For a full training pipeline please use [ddsp/training/ddsp_run.py](https://github.com/magenta/ddsp/blob/main/ddsp/training/README.md#train-1) as in the [train_autoencoder.ipynb](https://github.com/magenta/ddsp/blob/main/ddsp/colab/demos/train_autoencoder.ipynb)_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "both",
        "id": "S_jXCnwZ2QYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e464263-b450-40c4-b274-69d4473fb4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# Install and import dependencies\n",
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp\n",
        "\n",
        "# Ignore a bunch of deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "\n",
        "import ddsp\n",
        "from ddsp.training import (data, decoders, encoders, models, preprocessing, \n",
        "                           train_util, trainers)\n",
        "from ddsp.colab.colab_utils import play, specplot, DEFAULT_SAMPLE_RATE\n",
        "import gin\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khYj8yiMDxGL"
      },
      "source": [
        "# Get a batch of data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVjqNH1R535M",
        "outputId": "1cfa2fbe-3fc3-4d68-ebf8-d91b1218e197"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from absl import logging\n",
        "from ddsp.spectral_ops import CREPE_FRAME_SIZE\n",
        "from ddsp.spectral_ops import CREPE_SAMPLE_RATE\n",
        "from ddsp.spectral_ops import get_framed_lengths\n",
        "import gin\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "class DataProvider(object):\n",
        "  \"\"\"Base class for returning a dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, sample_rate, frame_rate):\n",
        "    \"\"\"DataProvider constructor.\n",
        "    Args:\n",
        "      sample_rate: Sample rate of audio in the dataset.\n",
        "      frame_rate: Frame rate of features in the dataset.\n",
        "    \"\"\"\n",
        "    self._sample_rate = sample_rate\n",
        "    self._frame_rate = frame_rate\n",
        "\n",
        "  @property\n",
        "  def sample_rate(self):\n",
        "    \"\"\"Return dataset sample rate, must be defined in the constructor.\"\"\"\n",
        "    return self._sample_rate\n",
        "\n",
        "  @property\n",
        "  def frame_rate(self):\n",
        "    \"\"\"Return dataset feature frame rate, must be defined in the constructor.\"\"\"\n",
        "    return self._frame_rate\n",
        "\n",
        "  def get_dataset(self, shuffle):\n",
        "    \"\"\"A method that returns a tf.data.Dataset.\"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def get_batch(self,\n",
        "                batch_size,\n",
        "                shuffle=True,\n",
        "                repeats=-1,\n",
        "                drop_remainder=True):\n",
        "    \"\"\"Read dataset.\n",
        "    Args:\n",
        "      batch_size: Size of batch.\n",
        "      shuffle: Whether to shuffle the examples.\n",
        "      repeats: Number of times to repeat dataset. -1 for endless repeats.\n",
        "      drop_remainder: Whether the last batch should be dropped.\n",
        "    Returns:\n",
        "      A batched tf.data.Dataset.\n",
        "    \"\"\"\n",
        "    dataset = self.get_dataset(shuffle)\n",
        "    dataset = dataset.repeat(repeats)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
        "    dataset = dataset.prefetch(buffer_size=_AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "class TFRecordProvider(DataProvider):\n",
        "  \"\"\"Class for reading TFRecords and returning a dataset.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               centered=False):\n",
        "    \"\"\"RecordProvider constructor.\"\"\"\n",
        "    super().__init__(sample_rate, frame_rate)\n",
        "    self._file_pattern = file_pattern or self.default_file_pattern\n",
        "    self._audio_length = example_secs * sample_rate\n",
        "    self._audio_16k_length = example_secs * CREPE_SAMPLE_RATE\n",
        "    self._feature_length = self.get_feature_length(centered)\n",
        "\n",
        "\n",
        "  def get_feature_length(self, centered):\n",
        "    \"\"\"Take into account center padding to get number of frames.\"\"\"\n",
        "    # Number of frames is independent of frame size for \"center/same\" padding.\n",
        "    hop_size = CREPE_SAMPLE_RATE / self.frame_rate\n",
        "    padding = 'center' if centered else 'same'\n",
        "    return get_framed_lengths(\n",
        "        self._audio_16k_length, CREPE_FRAME_SIZE, hop_size, padding)[0]\n",
        "\n",
        "  @property\n",
        "  def default_file_pattern(self):\n",
        "    \"\"\"Used if file_pattern is not provided to constructor.\"\"\"\n",
        "    raise NotImplementedError(\n",
        "        'You must pass a \"file_pattern\" argument to the constructor or '\n",
        "        'choose a FileDataProvider with a default_file_pattern.')\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    \"\"\"Read dataset.\n",
        "    Args:\n",
        "      shuffle: Whether to shuffle the files.\n",
        "    Returns:\n",
        "      dataset: A tf.dataset that reads from the TFRecord.\n",
        "    \"\"\"\n",
        "    def parse_tfexample(record):\n",
        "      return tf.io.parse_single_example(record, self.features_dict)\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=tf.data.TFRecordDataset,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=_AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample, num_parallel_calls=_AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    \"\"\"Dictionary of features to read from dataset.\"\"\"\n",
        "    return {\n",
        "        'audio':\n",
        "            tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "        'f0_hz':\n",
        "            tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "        'f0_confidence':\n",
        "            tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "        'loudness_db':\n",
        "            tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "    }"
      ],
      "metadata": {
        "id": "0c96yljr7ueM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "IzzaWKxVkYms",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "77e3f20e-3c72-4f35-fff9-ac0fa4ab32fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_3\"> </div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x442.347 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get a single example from NSynth.\n",
        "# Takes a few seconds to load from GCS.\n",
        "import glob\n",
        "\n",
        "_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "filenames_full = glob.glob(\"/content/drive/MyDrive/NSYNTH_GAN/mallet/train/*.tfrecord\")\n",
        "data_provider = TFRecordProvider(\n",
        "    \"/content/drive/MyDrive/NSYNTH_GAN/mallet/train/*.tfrecord\"\n",
        ")\n",
        "dataset = data_provider.get_batch(batch_size=1, shuffle=False).take(1).repeat()\n",
        "batch = next(iter(dataset))\n",
        "audio = batch['audio']\n",
        "n_samples = audio.shape[1]\n",
        "\n",
        "specplot(audio)\n",
        "play(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acGO0ifg0I3k"
      },
      "source": [
        "# Get a distribution strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "VUlAeW40Wsvr"
      },
      "outputs": [],
      "source": [
        "strategy = train_util.get_strategy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch[\"f0/confidence\"])\n",
        "batch[\"f0/confidence\"]"
      ],
      "metadata": {
        "id": "nijZir9eO8RY",
        "outputId": "af270e90-2b97-4995-c999-d754a764518f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.93773353 0.9452007  0.9449954  0.94677985 0.9500225  0.9442419\n",
            "  0.9516877  0.9541291  0.95147645 0.9489774  0.9571699  0.9511798\n",
            "  0.9456401  0.95614195 0.95160943 0.9398309  0.94929576 0.9497913\n",
            "  0.9439302  0.9446571  0.9476501  0.9394771  0.9335408  0.9433749\n",
            "  0.9443735  0.9304441  0.9416572  0.93890077 0.93091744 0.94296217\n",
            "  0.94381714 0.93011    0.9392348  0.93392503 0.929463   0.92636013\n",
            "  0.9317428  0.93493485 0.9192259  0.937116   0.9326004  0.9166105\n",
            "  0.9338255  0.9342736  0.923508   0.9348152  0.9357728  0.9272884\n",
            "  0.92266345 0.9256804  0.9312862  0.92052066 0.9327774  0.93385607\n",
            "  0.9126848  0.9234666  0.9220051  0.9135505  0.93121195 0.93198216\n",
            "  0.92891073 0.9284665  0.93140155 0.9248129  0.9141939  0.9240655\n",
            "  0.92860323 0.919415   0.93237054 0.9278046  0.9117222  0.92837995\n",
            "  0.9234501  0.9193841  0.93269217 0.9325123  0.9263015  0.92211556\n",
            "  0.9274379  0.92752564 0.91878635 0.92827904 0.93128616 0.9154526\n",
            "  0.92520875 0.920659   0.9121195  0.93025506 0.9314456  0.9262608\n",
            "  0.9342948  0.9347687  0.9231267  0.91982055 0.92678547 0.92871225\n",
            "  0.9214432  0.93279225 0.9327966  0.9140681  0.9251406  0.9192195\n",
            "  0.91225106 0.9326019  0.93386936 0.9299915  0.929348   0.9340885\n",
            "  0.9255171  0.9161792  0.92603266 0.930249   0.92202187 0.93294406\n",
            "  0.92803705 0.9129567  0.9303066  0.9238764  0.9192674  0.9337045\n",
            "  0.93302816 0.9264785  0.9233231  0.9285641  0.9277729  0.92041385\n",
            "  0.9295358  0.93209934 0.91663116 0.926148   0.9214833  0.9129503\n",
            "  0.9309742  0.931762   0.9267258  0.93470526 0.9352237  0.923279\n",
            "  0.9203773  0.9275124  0.92891526 0.9218313  0.93300045 0.9329847\n",
            "  0.91449034 0.9253273  0.9192239  0.91238844 0.9327942  0.9341022\n",
            "  0.9300804  0.9297091  0.9344728  0.9255941  0.91649467 0.92636824\n",
            "  0.9303924  0.9222437  0.9332031  0.9283099  0.9130621  0.9302629\n",
            "  0.9236506  0.91893613 0.9337704  0.9330503  0.9266664  0.92344236\n",
            "  0.9287125  0.92761946 0.9201497  0.9294683  0.9321307  0.9168114\n",
            "  0.92623234 0.9216992  0.91291875 0.93108296 0.9316799  0.9265977\n",
            "  0.9347602  0.9350943  0.9232613  0.9204341  0.9275464  0.92893493\n",
            "  0.92183566 0.9328729  0.9329854  0.9146617  0.9252559  0.9191187\n",
            "  0.9123019  0.93273187 0.93412507 0.93000364 0.92991817 0.9345952\n",
            "  0.9254787  0.91668355 0.9265559  0.93037647 0.9223608  0.93339837\n",
            "  0.9285331  0.9131454  0.930105   0.92349756 0.918748   0.9337698\n",
            "  0.9331799  0.926842   0.92363715 0.9288883  0.9275289  0.91990554\n",
            "  0.9293852  0.9321228  0.91699916 0.92629796 0.92190653 0.9128828\n",
            "  0.93121237 0.9315663  0.9264124  0.9348141  0.9349334  0.9231324\n",
            "  0.92049456 0.92758    0.928997   0.9219078  0.9327655  0.9330131\n",
            "  0.91481125 0.92519176 0.91904163 0.9122877  0.93267596 0.93418586\n",
            "  0.9299668  0.9301553  0.9347427  0.9253626  0.9167501  0.9266728\n",
            "  0.9301466  0.92236674 0.9334655  0.928777   0.91325045 0.9299594\n",
            "  0.9231672  0.91839445 0.93372065 0.93314    0.92689764 0.92367345\n",
            "  0.9290478  0.9273581  0.91972214 0.9292908  0.93203354 0.91713804\n",
            "  0.9263096  0.92210466 0.91288173 0.93134856 0.9314323  0.92621875\n",
            "  0.93489015 0.9347755  0.92307794 0.92061067 0.9275931  0.9290155\n",
            "  0.9219292  0.9326699  0.9331525  0.91480964 0.92509604 0.91882145\n",
            "  0.91202426 0.93261    0.93417007 0.92990726 0.93042344 0.93489397\n",
            "  0.92532945 0.91696763 0.92688155 0.93004453 0.92255116 0.93373007\n",
            "  0.92889273 0.91310537 0.9297572  0.92299366 0.9181733  0.9336628\n",
            "  0.93338513 0.9270497  0.9240865  0.92921925 0.9271548  0.9193731\n",
            "  0.92898834 0.932011   0.91762185 0.92660207 0.9223675  0.9128634\n",
            "  0.9314598  0.9311309  0.9259859  0.9349642  0.9347679  0.92328036\n",
            "  0.92080766 0.9278159  0.9289173  0.92196083 0.9326197  0.93316066\n",
            "  0.9148836  0.9249772  0.9187379  0.9120105  0.9324814  0.9340824\n",
            "  0.92974794 0.9306034  0.93497884 0.92507315 0.9169049  0.9269006\n",
            "  0.9296993  0.9224839  0.93358433 0.9291668  0.9132321  0.92962575\n",
            "  0.9222389  0.91728127 0.9335824  0.93309534 0.9270439  0.92402005\n",
            "  0.92964685 0.92740047 0.91975105 0.9295472  0.9323696  0.91822994\n",
            "  0.92687166 0.9230193  0.91363406 0.9318116  0.9309077  0.92552507\n",
            "  0.9346454  0.9341964  0.9229512  0.9202766  0.92705536 0.9285017\n",
            "  0.92182684 0.93243456 0.9331747  0.91480505 0.9247445  0.91861594\n",
            "  0.9121014  0.9326652  0.93411434 0.92990166 0.9308436  0.93490696\n",
            "  0.92564434 0.91687477 0.927225   0.92975557 0.9229412  0.93412256\n",
            "  0.9297155  0.91373456 0.9293864  0.9227357  0.9181737  0.9333879\n",
            "  0.9331335  0.9264141  0.9241872  0.92978513 0.92720044 0.9194577\n",
            "  0.92895204 0.93168455 0.9175433  0.9264988  0.92242926 0.91226214\n",
            "  0.93081766 0.93059623 0.9248363  0.93453074 0.9344065  0.92350173\n",
            "  0.9210588  0.9281392  0.9284003  0.92209965 0.932684   0.9328607\n",
            "  0.91475797 0.9254516  0.91885436 0.91305363 0.9328718  0.93425107\n",
            "  0.9298152  0.9317144  0.9352921  0.92344695 0.91577685 0.9244515\n",
            "  0.92749083 0.9208056  0.9317075  0.9295503  0.9136586  0.930048\n",
            "  0.9221504  0.91718864 0.93174213 0.9313928  0.9226804  0.9208809\n",
            "  0.92780834 0.9250606  0.9175215  0.9272733  0.93045235 0.91527975\n",
            "  0.9262997  0.91945314 0.90922886 0.9275629  0.9274858  0.92497456\n",
            "  0.9329277  0.93015325 0.9220824  0.911075   0.92631435 0.9250767\n",
            "  0.91785884 0.9288945  0.9258328  0.9056406  0.91962516 0.90563285\n",
            "  0.901862   0.9206914  0.9268472  0.92214215 0.9247588  0.9316753\n",
            "  0.91892064 0.90594447 0.9201542  0.9153938  0.9030229  0.91982615\n",
            "  0.9154455  0.9023643  0.9191436  0.9099176  0.8999895  0.9266621\n",
            "  0.9155308  0.9149483  0.90473497 0.91324115 0.90364546 0.8957199\n",
            "  0.908793   0.91163456 0.90984786 0.92005146 0.91407424 0.90060794\n",
            "  0.9182481  0.90910053 0.90237826 0.90289557 0.89426386 0.8796041\n",
            "  0.8808498  0.88192034 0.8480327  0.74557006 0.60252416 0.48249564\n",
            "  0.40420708 0.37740833 0.15413195 0.16021329 0.13071379 0.1319432\n",
            "  0.10673741 0.04911304 0.0813472  0.08298764 0.15149334 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]], shape=(1, 1000), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
              "array([[0.93773353, 0.9452007 , 0.9449954 , 0.94677985, 0.9500225 ,\n",
              "        0.9442419 , 0.9516877 , 0.9541291 , 0.95147645, 0.9489774 ,\n",
              "        0.9571699 , 0.9511798 , 0.9456401 , 0.95614195, 0.95160943,\n",
              "        0.9398309 , 0.94929576, 0.9497913 , 0.9439302 , 0.9446571 ,\n",
              "        0.9476501 , 0.9394771 , 0.9335408 , 0.9433749 , 0.9443735 ,\n",
              "        0.9304441 , 0.9416572 , 0.93890077, 0.93091744, 0.94296217,\n",
              "        0.94381714, 0.93011   , 0.9392348 , 0.93392503, 0.929463  ,\n",
              "        0.92636013, 0.9317428 , 0.93493485, 0.9192259 , 0.937116  ,\n",
              "        0.9326004 , 0.9166105 , 0.9338255 , 0.9342736 , 0.923508  ,\n",
              "        0.9348152 , 0.9357728 , 0.9272884 , 0.92266345, 0.9256804 ,\n",
              "        0.9312862 , 0.92052066, 0.9327774 , 0.93385607, 0.9126848 ,\n",
              "        0.9234666 , 0.9220051 , 0.9135505 , 0.93121195, 0.93198216,\n",
              "        0.92891073, 0.9284665 , 0.93140155, 0.9248129 , 0.9141939 ,\n",
              "        0.9240655 , 0.92860323, 0.919415  , 0.93237054, 0.9278046 ,\n",
              "        0.9117222 , 0.92837995, 0.9234501 , 0.9193841 , 0.93269217,\n",
              "        0.9325123 , 0.9263015 , 0.92211556, 0.9274379 , 0.92752564,\n",
              "        0.91878635, 0.92827904, 0.93128616, 0.9154526 , 0.92520875,\n",
              "        0.920659  , 0.9121195 , 0.93025506, 0.9314456 , 0.9262608 ,\n",
              "        0.9342948 , 0.9347687 , 0.9231267 , 0.91982055, 0.92678547,\n",
              "        0.92871225, 0.9214432 , 0.93279225, 0.9327966 , 0.9140681 ,\n",
              "        0.9251406 , 0.9192195 , 0.91225106, 0.9326019 , 0.93386936,\n",
              "        0.9299915 , 0.929348  , 0.9340885 , 0.9255171 , 0.9161792 ,\n",
              "        0.92603266, 0.930249  , 0.92202187, 0.93294406, 0.92803705,\n",
              "        0.9129567 , 0.9303066 , 0.9238764 , 0.9192674 , 0.9337045 ,\n",
              "        0.93302816, 0.9264785 , 0.9233231 , 0.9285641 , 0.9277729 ,\n",
              "        0.92041385, 0.9295358 , 0.93209934, 0.91663116, 0.926148  ,\n",
              "        0.9214833 , 0.9129503 , 0.9309742 , 0.931762  , 0.9267258 ,\n",
              "        0.93470526, 0.9352237 , 0.923279  , 0.9203773 , 0.9275124 ,\n",
              "        0.92891526, 0.9218313 , 0.93300045, 0.9329847 , 0.91449034,\n",
              "        0.9253273 , 0.9192239 , 0.91238844, 0.9327942 , 0.9341022 ,\n",
              "        0.9300804 , 0.9297091 , 0.9344728 , 0.9255941 , 0.91649467,\n",
              "        0.92636824, 0.9303924 , 0.9222437 , 0.9332031 , 0.9283099 ,\n",
              "        0.9130621 , 0.9302629 , 0.9236506 , 0.91893613, 0.9337704 ,\n",
              "        0.9330503 , 0.9266664 , 0.92344236, 0.9287125 , 0.92761946,\n",
              "        0.9201497 , 0.9294683 , 0.9321307 , 0.9168114 , 0.92623234,\n",
              "        0.9216992 , 0.91291875, 0.93108296, 0.9316799 , 0.9265977 ,\n",
              "        0.9347602 , 0.9350943 , 0.9232613 , 0.9204341 , 0.9275464 ,\n",
              "        0.92893493, 0.92183566, 0.9328729 , 0.9329854 , 0.9146617 ,\n",
              "        0.9252559 , 0.9191187 , 0.9123019 , 0.93273187, 0.93412507,\n",
              "        0.93000364, 0.92991817, 0.9345952 , 0.9254787 , 0.91668355,\n",
              "        0.9265559 , 0.93037647, 0.9223608 , 0.93339837, 0.9285331 ,\n",
              "        0.9131454 , 0.930105  , 0.92349756, 0.918748  , 0.9337698 ,\n",
              "        0.9331799 , 0.926842  , 0.92363715, 0.9288883 , 0.9275289 ,\n",
              "        0.91990554, 0.9293852 , 0.9321228 , 0.91699916, 0.92629796,\n",
              "        0.92190653, 0.9128828 , 0.93121237, 0.9315663 , 0.9264124 ,\n",
              "        0.9348141 , 0.9349334 , 0.9231324 , 0.92049456, 0.92758   ,\n",
              "        0.928997  , 0.9219078 , 0.9327655 , 0.9330131 , 0.91481125,\n",
              "        0.92519176, 0.91904163, 0.9122877 , 0.93267596, 0.93418586,\n",
              "        0.9299668 , 0.9301553 , 0.9347427 , 0.9253626 , 0.9167501 ,\n",
              "        0.9266728 , 0.9301466 , 0.92236674, 0.9334655 , 0.928777  ,\n",
              "        0.91325045, 0.9299594 , 0.9231672 , 0.91839445, 0.93372065,\n",
              "        0.93314   , 0.92689764, 0.92367345, 0.9290478 , 0.9273581 ,\n",
              "        0.91972214, 0.9292908 , 0.93203354, 0.91713804, 0.9263096 ,\n",
              "        0.92210466, 0.91288173, 0.93134856, 0.9314323 , 0.92621875,\n",
              "        0.93489015, 0.9347755 , 0.92307794, 0.92061067, 0.9275931 ,\n",
              "        0.9290155 , 0.9219292 , 0.9326699 , 0.9331525 , 0.91480964,\n",
              "        0.92509604, 0.91882145, 0.91202426, 0.93261   , 0.93417007,\n",
              "        0.92990726, 0.93042344, 0.93489397, 0.92532945, 0.91696763,\n",
              "        0.92688155, 0.93004453, 0.92255116, 0.93373007, 0.92889273,\n",
              "        0.91310537, 0.9297572 , 0.92299366, 0.9181733 , 0.9336628 ,\n",
              "        0.93338513, 0.9270497 , 0.9240865 , 0.92921925, 0.9271548 ,\n",
              "        0.9193731 , 0.92898834, 0.932011  , 0.91762185, 0.92660207,\n",
              "        0.9223675 , 0.9128634 , 0.9314598 , 0.9311309 , 0.9259859 ,\n",
              "        0.9349642 , 0.9347679 , 0.92328036, 0.92080766, 0.9278159 ,\n",
              "        0.9289173 , 0.92196083, 0.9326197 , 0.93316066, 0.9148836 ,\n",
              "        0.9249772 , 0.9187379 , 0.9120105 , 0.9324814 , 0.9340824 ,\n",
              "        0.92974794, 0.9306034 , 0.93497884, 0.92507315, 0.9169049 ,\n",
              "        0.9269006 , 0.9296993 , 0.9224839 , 0.93358433, 0.9291668 ,\n",
              "        0.9132321 , 0.92962575, 0.9222389 , 0.91728127, 0.9335824 ,\n",
              "        0.93309534, 0.9270439 , 0.92402005, 0.92964685, 0.92740047,\n",
              "        0.91975105, 0.9295472 , 0.9323696 , 0.91822994, 0.92687166,\n",
              "        0.9230193 , 0.91363406, 0.9318116 , 0.9309077 , 0.92552507,\n",
              "        0.9346454 , 0.9341964 , 0.9229512 , 0.9202766 , 0.92705536,\n",
              "        0.9285017 , 0.92182684, 0.93243456, 0.9331747 , 0.91480505,\n",
              "        0.9247445 , 0.91861594, 0.9121014 , 0.9326652 , 0.93411434,\n",
              "        0.92990166, 0.9308436 , 0.93490696, 0.92564434, 0.91687477,\n",
              "        0.927225  , 0.92975557, 0.9229412 , 0.93412256, 0.9297155 ,\n",
              "        0.91373456, 0.9293864 , 0.9227357 , 0.9181737 , 0.9333879 ,\n",
              "        0.9331335 , 0.9264141 , 0.9241872 , 0.92978513, 0.92720044,\n",
              "        0.9194577 , 0.92895204, 0.93168455, 0.9175433 , 0.9264988 ,\n",
              "        0.92242926, 0.91226214, 0.93081766, 0.93059623, 0.9248363 ,\n",
              "        0.93453074, 0.9344065 , 0.92350173, 0.9210588 , 0.9281392 ,\n",
              "        0.9284003 , 0.92209965, 0.932684  , 0.9328607 , 0.91475797,\n",
              "        0.9254516 , 0.91885436, 0.91305363, 0.9328718 , 0.93425107,\n",
              "        0.9298152 , 0.9317144 , 0.9352921 , 0.92344695, 0.91577685,\n",
              "        0.9244515 , 0.92749083, 0.9208056 , 0.9317075 , 0.9295503 ,\n",
              "        0.9136586 , 0.930048  , 0.9221504 , 0.91718864, 0.93174213,\n",
              "        0.9313928 , 0.9226804 , 0.9208809 , 0.92780834, 0.9250606 ,\n",
              "        0.9175215 , 0.9272733 , 0.93045235, 0.91527975, 0.9262997 ,\n",
              "        0.91945314, 0.90922886, 0.9275629 , 0.9274858 , 0.92497456,\n",
              "        0.9329277 , 0.93015325, 0.9220824 , 0.911075  , 0.92631435,\n",
              "        0.9250767 , 0.91785884, 0.9288945 , 0.9258328 , 0.9056406 ,\n",
              "        0.91962516, 0.90563285, 0.901862  , 0.9206914 , 0.9268472 ,\n",
              "        0.92214215, 0.9247588 , 0.9316753 , 0.91892064, 0.90594447,\n",
              "        0.9201542 , 0.9153938 , 0.9030229 , 0.91982615, 0.9154455 ,\n",
              "        0.9023643 , 0.9191436 , 0.9099176 , 0.8999895 , 0.9266621 ,\n",
              "        0.9155308 , 0.9149483 , 0.90473497, 0.91324115, 0.90364546,\n",
              "        0.8957199 , 0.908793  , 0.91163456, 0.90984786, 0.92005146,\n",
              "        0.91407424, 0.90060794, 0.9182481 , 0.90910053, 0.90237826,\n",
              "        0.90289557, 0.89426386, 0.8796041 , 0.8808498 , 0.88192034,\n",
              "        0.8480327 , 0.74557006, 0.60252416, 0.48249564, 0.40420708,\n",
              "        0.37740833, 0.15413195, 0.16021329, 0.13071379, 0.1319432 ,\n",
              "        0.10673741, 0.04911304, 0.0813472 , 0.08298764, 0.15149334,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch.keys())"
      ],
      "metadata": {
        "id": "CtPjCQxvQNqA",
        "outputId": "36bb281d-8d87-42c3-8a38-50694f8ad249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['audio'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#batch[new_key] = batch.pop(old_key)\n",
        "\n",
        "def rename_features(batch):\n",
        "  batch['f0_confidence'] = batch.pop('f0/confidence')\n",
        "\n",
        "  batch['f0_hz'] = batch.pop('f0/hz')\n",
        "\n",
        "  batch['loudness_db'] = batch.pop('loudness/db')\n",
        "\n",
        "  return batch"
      ],
      "metadata": {
        "id": "waFrG5GZSghE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch.keys())"
      ],
      "metadata": {
        "id": "hKNWnccLTHy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_keys = batch.keys()\n",
        "new_keys = ['audio', 'f0_confidence', 'f0_hz', 'loudness_db']\n",
        "print(zip(batch_keys,new_keys))\n",
        "for key, key2 in zip(batch_keys,new_keys):\n",
        "  print(key, key2)\n"
      ],
      "metadata": {
        "id": "jqeuIt8pP2P-",
        "outputId": "e29be9d7-ffc2-42a1-9334-7eeb7061c670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<zip object at 0x7f0a908ddbc0>\n",
            "audio audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0oFE75-A-Fk",
        "outputId": "0055dc38-c938-40fd-bac8-bfc996af1904"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00445393 0.10546707 0.2777211  ... 0.         0.         0.        ]], shape=(1, 64000), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op0V8onI0VUK"
      },
      "source": [
        "# Get model and trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWZQXFLehCU0"
      },
      "source": [
        "## python "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "HCqXRY1KeX8S"
      },
      "outputs": [],
      "source": [
        "TIME_STEPS = 1000\n",
        "\n",
        "# Create Neural Networks.\n",
        "preprocessor = preprocessing.F0LoudnessPreprocessor(time_steps=TIME_STEPS)\n",
        "\n",
        "decoder = decoders.RnnFcDecoder(rnn_channels = 256,\n",
        "                                rnn_type = 'gru',\n",
        "                                ch = 256,\n",
        "                                layers_per_stack = 1,\n",
        "                                input_keys = ('ld_scaled', 'f0_scaled'),\n",
        "                                output_splits = (('amps', 1),\n",
        "                                                 ('harmonic_distribution', 45),\n",
        "                                                 ('noise_magnitudes', 45)))\n",
        "\n",
        "# Create Processors.\n",
        "harmonic = ddsp.synths.Harmonic(n_samples=n_samples, \n",
        "                                sample_rate=sample_rate,\n",
        "                                name='harmonic')\n",
        "\n",
        "noise = ddsp.synths.FilteredNoise(window_size=0,\n",
        "                                  initial_bias=-10.0,\n",
        "                                  name='noise')\n",
        "add = ddsp.processors.Add(name='add')\n",
        "\n",
        "# Create ProcessorGroup.\n",
        "dag = [(harmonic, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
        "       (noise, ['noise_magnitudes']),\n",
        "       (add, ['noise/signal', 'harmonic/signal'])]\n",
        "\n",
        "processor_group = ddsp.processors.ProcessorGroup(dag=dag,\n",
        "                                                 name='processor_group')\n",
        "\n",
        "\n",
        "# Loss_functions\n",
        "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
        "                                         mag_weight=1.0,\n",
        "                                         logmag_weight=1.0)\n",
        "\n",
        "with strategy.scope():\n",
        "  # Put it together in a model.\n",
        "  model = models.Autoencoder(preprocessor=preprocessor,\n",
        "                             encoder=None,\n",
        "                             decoder=decoder,\n",
        "                             processor_group=processor_group,\n",
        "                             losses=[spectral_loss])\n",
        "  trainer = trainers.Trainer(model, strategy, learning_rate=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAZgDMV9hGyp"
      },
      "source": [
        "## or [`gin`](https://github.com/google/gin-config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JPmTwQshVya"
      },
      "outputs": [],
      "source": [
        "gin_string = \"\"\"\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "\n",
        "# Preprocessor\n",
        "models.Autoencoder.preprocessor = @preprocessing.F0LoudnessPreprocessor()\n",
        "preprocessing.F0LoudnessPreprocessor.time_steps = 1000\n",
        "\n",
        "\n",
        "# Encoder\n",
        "models.Autoencoder.encoder = None\n",
        "\n",
        "# Decoder\n",
        "models.Autoencoder.decoder = @decoders.RnnFcDecoder()\n",
        "decoders.RnnFcDecoder.rnn_channels = 256\n",
        "decoders.RnnFcDecoder.rnn_type = 'gru'\n",
        "decoders.RnnFcDecoder.ch = 256\n",
        "decoders.RnnFcDecoder.layers_per_stack = 1\n",
        "decoders.RnnFcDecoder.input_keys = ('ld_scaled', 'f0_scaled')\n",
        "decoders.RnnFcDecoder.output_splits = (('amps', 1),\n",
        "                                       ('harmonic_distribution', 20),\n",
        "                                       ('noise_magnitudes', 20))\n",
        "\n",
        "# ProcessorGroup\n",
        "models.Autoencoder.processor_group = @processors.ProcessorGroup()\n",
        "\n",
        "processors.ProcessorGroup.dag = [\n",
        "  (@harmonic/synths.Harmonic(),\n",
        "    ['amps', 'harmonic_distribution', 'f0_hz']),\n",
        "  (@noise/synths.FilteredNoise(),\n",
        "    ['noise_magnitudes']),\n",
        "  (@add/processors.Add(),\n",
        "    ['noise/signal', 'harmonic/signal']),\n",
        "]\n",
        "\n",
        "# Harmonic Synthesizer\n",
        "harmonic/synths.Harmonic.name = 'harmonic'\n",
        "harmonic/synths.Harmonic.n_samples = 64000\n",
        "harmonic/synths.Harmonic.scale_fn = @core.exp_sigmoid\n",
        "\n",
        "# Filtered Noise Synthesizer\n",
        "noise/synths.FilteredNoise.name = 'noise'\n",
        "noise/synths.FilteredNoise.n_samples = 64000\n",
        "noise/synths.FilteredNoise.window_size = 0\n",
        "noise/synths.FilteredNoise.scale_fn = @core.exp_sigmoid\n",
        "noise/synths.FilteredNoise.initial_bias = -10.0\n",
        "\n",
        "# Add\n",
        "add/processors.Add.name = 'add'\n",
        "\n",
        "models.Autoencoder.losses = [\n",
        "    @losses.SpectralLoss(),\n",
        "]\n",
        "losses.SpectralLoss.loss_type = 'L1'\n",
        "losses.SpectralLoss.mag_weight = 1.0\n",
        "losses.SpectralLoss.logmag_weight = 1.0\n",
        "\"\"\"\n",
        "\n",
        "with gin.unlock_config():\n",
        "  gin.parse_config(gin_string)\n",
        "\n",
        "with strategy.scope():\n",
        "  # Autoencoder arguments are filled by gin.\n",
        "  model = ddsp.training.models.Autoencoder()\n",
        "  trainer = trainers.Trainer(model, strategy, learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnnxpYbRrPrp"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGvCE5BbrWTU"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1lQW604_QWm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f259cd3d-f05a-4038-eabe-15fcc3a7fbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"autoencoder_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " f0_loudness_preprocessor_2   multiple                 0         \n",
            " (F0LoudnessPreprocessor)                                        \n",
            "                                                                 \n",
            " rnn_fc_decoder_2 (RnnFcDeco  multiple                 814171    \n",
            " der)                                                            \n",
            "                                                                 \n",
            " processor_group (ProcessorG  multiple                 0         \n",
            " roup)                                                           \n",
            "                                                                 \n",
            " spectral_loss (SpectralLoss  multiple                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 814,171\n",
            "Trainable params: 814,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build model, easiest to just run forward pass.\n",
        "dataset = trainer.distribute_dataset(dataset)\n",
        "trainer.build(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFEqt6e1DsqG"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2022 The DDSP Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Library of Trainer objects that define traning step and wrap optimizer.\"\"\"\n",
        "\n",
        "import time\n",
        "\n",
        "from absl import logging\n",
        "from ddsp.training import train_util\n",
        "import gin\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "\n",
        "@gin.configurable\n",
        "#@gin.enter_interactive_mode()\n",
        "class Trainer(object):\n",
        "  \"\"\"Class to bind an optimizer, model, strategy, and training step function.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               model,\n",
        "               strategy,\n",
        "               checkpoints_to_keep=100,\n",
        "               learning_rate=0.001,\n",
        "               lr_decay_steps=10000,\n",
        "               lr_decay_rate=0.98,\n",
        "               grad_clip_norm=3.0,\n",
        "               restore_keys=None):\n",
        "    \"\"\"Constructor.\n",
        "\n",
        "    Args:\n",
        "      model: Model to train.\n",
        "      strategy: A distribution strategy.\n",
        "      checkpoints_to_keep: Max number of checkpoints before deleting oldest.\n",
        "      learning_rate: Scalar initial learning rate.\n",
        "      lr_decay_steps: Exponential decay timescale.\n",
        "      lr_decay_rate: Exponential decay magnitude.\n",
        "      grad_clip_norm: Norm level by which to clip gradients.\n",
        "      restore_keys: List of names of model properties to restore. If no keys are\n",
        "        passed, restore the whole model.\n",
        "    \"\"\"\n",
        "    self.model = model\n",
        "    self.strategy = strategy\n",
        "    self.checkpoints_to_keep = checkpoints_to_keep\n",
        "    self.grad_clip_norm = grad_clip_norm\n",
        "    self.restore_keys = restore_keys\n",
        "\n",
        "    # Create an optimizer.\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=learning_rate,\n",
        "        decay_steps=lr_decay_steps,\n",
        "        decay_rate=lr_decay_rate)\n",
        "\n",
        "    with self.strategy.scope():\n",
        "      self.optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "  def get_checkpoint(self, model=None):\n",
        "    \"\"\"Model arg can also be a tf.train.Checkpoint(**dict(submodules)).\"\"\"\n",
        "    model = model or self.model  # Default to full model.\n",
        "    return tf.train.Checkpoint(model=model, optimizer=self.optimizer)\n",
        "\n",
        "  def save(self, save_dir):\n",
        "    \"\"\"Saves model and optimizer to a checkpoint.\"\"\"\n",
        "    # Saving weights in checkpoint format because saved_model requires\n",
        "    # handling variable batch size, which some synths and effects can't.\n",
        "    start_time = time.time()\n",
        "    checkpoint = self.get_checkpoint()\n",
        "    manager = tf.train.CheckpointManager(\n",
        "        checkpoint, directory=save_dir, max_to_keep=self.checkpoints_to_keep)\n",
        "    step = self.step.numpy()\n",
        "    manager.save(checkpoint_number=step)\n",
        "    logging.info('Saved checkpoint to %s at step %s', save_dir, step)\n",
        "    logging.info('Saving model took %.1f seconds', time.time() - start_time)\n",
        "\n",
        "  def restore(self, checkpoint_path, restore_keys=None):\n",
        "    \"\"\"Restore model and optimizer from a checkpoint if it exists.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_path: Path to checkpoint file or directory.\n",
        "      restore_keys: Optional list of strings for submodules to restore.\n",
        "\n",
        "    Raises:\n",
        "      FileNotFoundError: If no checkpoint is found.\n",
        "    \"\"\"\n",
        "    logging.info('Restoring from checkpoint...')\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Prefer function args over object properties.\n",
        "    restore_keys = restore_keys or self.restore_keys\n",
        "    if restore_keys is None:\n",
        "      # If no keys are passed, restore the whole model.\n",
        "      model = self.model\n",
        "      logging.info('Trainer restoring the full model')\n",
        "    else:\n",
        "      # Restore only sub-modules by building a new subgraph.\n",
        "      restore_dict = {k: getattr(self.model, k) for k in restore_keys}\n",
        "      model = tf.train.Checkpoint(**restore_dict)\n",
        "\n",
        "      logging.info('Trainer restoring model subcomponents:')\n",
        "      for k, v in restore_dict.items():\n",
        "        log_str = 'Restoring {}: {}'.format(k, v)\n",
        "        logging.info(log_str)\n",
        "\n",
        "    # Restore from latest checkpoint.\n",
        "    checkpoint = self.get_checkpoint(model)\n",
        "    latest_checkpoint = train_util.get_latest_checkpoint(checkpoint_path)\n",
        "    # checkpoint.restore must be within a strategy.scope() so that optimizer\n",
        "    # slot variables are mirrored.\n",
        "    with self.strategy.scope():\n",
        "      if restore_keys is None:\n",
        "        checkpoint.restore(latest_checkpoint)\n",
        "      else:\n",
        "        checkpoint.restore(latest_checkpoint).expect_partial()\n",
        "      logging.info('Loaded checkpoint %s', latest_checkpoint)\n",
        "    logging.info('Loading model took %.1f seconds', time.time() - start_time)\n",
        "\n",
        "  @property\n",
        "  def step(self):\n",
        "    \"\"\"The number of training steps completed.\"\"\"\n",
        "    return self.optimizer.iterations\n",
        "\n",
        "  def psum(self, x, axis=None):\n",
        "    \"\"\"Sum across processors.\"\"\"\n",
        "    return self.strategy.reduce(tf.distribute.ReduceOp.SUM, x, axis=axis)\n",
        "\n",
        "  def run(self, fn, *args, **kwargs):\n",
        "    \"\"\"Distribute and run function on processors.\"\"\"\n",
        "    return self.strategy.run(fn, args=args, kwargs=kwargs)\n",
        "\n",
        "  def build(self, batch):\n",
        "    \"\"\"Build the model by running a distributed batch through it.\"\"\"\n",
        "    logging.info('Building the model...')\n",
        "    _ = self.run(tf.function(self.model.__call__), batch)\n",
        "    self.model.summary()\n",
        "\n",
        "  def distribute_dataset(self, dataset):\n",
        "    \"\"\"Create a distributed dataset.\"\"\"\n",
        "    if isinstance(dataset, tf.data.Dataset):\n",
        "      return self.strategy.experimental_distribute_dataset(dataset)\n",
        "    else:\n",
        "      return dataset\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    \"\"\"Distributed training step.\"\"\"\n",
        "    # Wrap iterator in tf.function, slight speedup passing in iter vs batch.\n",
        "    batch = next(inputs) if hasattr(inputs, '__next__') else inputs\n",
        "    batch = rename_features(batch)\n",
        "    losses = self.run(self.step_fn, batch)\n",
        "    # Add up the scalar losses across replicas.\n",
        "    n_replicas = self.strategy.num_replicas_in_sync\n",
        "    return {k: self.psum(v, axis=None) / n_replicas for k, v in losses.items()}\n",
        "\n",
        "  @tf.function\n",
        "  def step_fn(self, batch):\n",
        "    \"\"\"Per-Replica training step.\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      _, losses = self.model(batch, return_losses=True, training=True)\n",
        "    # Clip and apply gradients.\n",
        "    grads = tape.gradient(losses['total_loss'], self.model.trainable_variables)\n",
        "    grads, _ = tf.clip_by_global_norm(grads, self.grad_clip_norm)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "    return losses\n",
        "\n",
        "\n",
        "@gin.configurable\n",
        "def get_trainer_class(trainer_class=Trainer):\n",
        "  \"\"\"Gin configurable function get a 'global' trainer for use in ddsp_run.py.\n",
        "\n",
        "  Args:\n",
        "    trainer_class: A trainer class such as `Trainer`.\n",
        "\n",
        "  Returns:\n",
        "    The 'global' trainer class specifieed in the gin config.\n",
        "  \"\"\"\n",
        "  return trainer_class\n"
      ],
      "metadata": {
        "id": "PT0UJe2eWbAf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "LWdoRIONDxri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20ef2602-bf6c-46ea-ef87-b4f55423ec52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.distribute.input_lib.DistributedIterator object at 0x7f0acf0a5cd0>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-3008648b8ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mres_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'step: {}\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__next__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag__.converted_call(hasattr, (inputs, '__next__'), None, fscope)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mn_replicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py\u001b[0m in \u001b[0;36mtf__run\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mtf__call_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wrapped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'_cfer_fn_cache[strategy]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cfer_fn_cache[strategy][fn]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do_return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retval_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__call_for_each_replica\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36melse_body_6\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                         \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py\u001b[0m in \u001b[0;36mtf__step_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_global_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/models/model.py\u001b[0m in \u001b[0;36mtf____call__\u001b[0;34m(self, return_losses, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_if_tf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag__.converted_call(isinstance, (a, dict), None, fscope)'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_losses_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, features, training)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mpg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_outputs_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\u001b[0m in \u001b[0;36mtf__encode\u001b[0;34m(self, features, training)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\u001b[0m in \u001b[0;36mif_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/nn.py\u001b[0m in \u001b[0;36mtf____call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ddsp/training/nn.py\u001b[0m in \u001b[0;36mif_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mif_body_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     raise ag__.converted_call(ag__.ld(TypeError), (f'''{ag__.converted_call(ag__.ld(len), (ag__.ld(inputs),), None, fscope)} input tensors extracted from inputs(including default args) but the layer expects {ag__.ld(self).n_inputs} tensors.\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0mInput\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mDefault\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_input_keys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py\", line 157, in train_step  *\n        losses = self.run(self.step_fn, batch)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py\", line 137, in run  *\n        return self.strategy.run(fn, args=args, kwargs=kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/trainers.py\", line 166, in step_fn  *\n        _, losses = self.model(batch, return_losses=True, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/model.py\", line 53, in __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filevat3j_i9.py\", line 11, in tf__call\n        features = ag__.converted_call(ag__.ld(self).encode, (ag__.ld(features),), dict(training=ag__.ld(training)), fscope)\n    File \"/tmp/__autograph_generated_filen07ecypw.py\", line 23, in tf__encode\n        ag__.if_stmt((ag__.ld(self).preprocessor is not None), if_body, else_body, get_state, set_state, (), 0)\n    File \"/tmp/__autograph_generated_filen07ecypw.py\", line 19, in if_body\n        ag__.converted_call(ag__.ld(features).update, (ag__.converted_call(ag__.ld(self).preprocessor, (ag__.ld(features),), dict(training=ag__.ld(training)), fscope),), None, fscope)\n    File \"/tmp/__autograph_generated_filen1072ocn.py\", line 122, in tf____call__\n        ag__.if_stmt((ag__.converted_call(ag__.ld(len), (ag__.ld(inputs),), None, fscope) != ag__.ld(self).n_inputs), if_body_3, else_body_3, get_state_7, set_state_7, (), 0)\n    File \"/tmp/__autograph_generated_filen1072ocn.py\", line 112, in if_body_3\n        raise ag__.converted_call(ag__.ld(TypeError), (f'''{ag__.converted_call(ag__.ld(len), (ag__.ld(inputs),), None, fscope)} input tensors extracted from inputs(including default args) but the layer expects {ag__.ld(self).n_inputs} tensors.\n\n    TypeError: Exception encountered when calling layer \"autoencoder_2\" (type Autoencoder).\n    \n    in user code:\n    \n        File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\", line 57, in call  *\n            features = self.encode(features, training=training)\n        File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/models/autoencoder.py\", line 41, in encode  *\n            features.update(self.preprocessor(features, training=training))\n        File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/nn.py\", line 197, in __call__  *\n            raise TypeError(f'{len(inputs)} input tensors extracted from inputs'\n    \n        TypeError: 1 input tensors extracted from inputs(including default args) but the layer expects 3 tensors.\n        Input keys: ListWrapper(['loudness_db', 'f0_hz'])\n        Default keys: ListWrapper(['audio'])\n        Default values: ListWrapper([None])\n        Input dictionaries: {'audio': <tf.Tensor 'args:0' shape=(1, 64000) dtype=float32>, 'f0/confidence': <tf.Tensor 'args_1:0' shape=(1, 1000) dtype=float32>, 'f0/hz': <tf.Tensor 'args_2:0' shape=(1, 1000) dtype=float32>, 'loudness/db': <tf.Tensor 'args_3:0' shape=(1, 1000) dtype=float32>}\n        Input Tensors (Args, Dicts, and Defaults): [<tf.Tensor 'args:0' shape=(1, 64000) dtype=float32>]\n        \n    \n    \n    Call arguments received by layer \"autoencoder_2\" (type Autoencoder):\n      • features={'audio': 'tf.Tensor(shape=(1, 64000), dtype=float32)', 'f0/confidence': 'tf.Tensor(shape=(1, 1000), dtype=float32)', 'f0/hz': 'tf.Tensor(shape=(1, 1000), dtype=float32)', 'loudness/db': 'tf.Tensor(shape=(1, 1000), dtype=float32)'}\n      • training=True\n"
          ]
        }
      ],
      "source": [
        "dataset_iter = iter(dataset)\n",
        "#dataset_iter = rename_features(dataset_iter)\n",
        "print(dataset_iter)\n",
        "for i in range(300):\n",
        "  losses = trainer.train_step(dataset_iter)\n",
        "  res_str = 'step: {}\\t'.format(i)\n",
        "  for k, v in losses.items():\n",
        "    res_str += '{}: {:.2f}\\t'.format(k, v)\n",
        "  print(res_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cj220vSF8_Y"
      },
      "source": [
        "# Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDU_FysURm_Z"
      },
      "outputs": [],
      "source": [
        "# Run a batch of predictions.\n",
        "start_time = time.time()\n",
        "controls =  model(next(dataset_iter))\n",
        "audio_gen = model.get_audio_from_outputs(controls)\n",
        "print('Prediction took %.1f seconds' % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlE5kkroHiFr"
      },
      "outputs": [],
      "source": [
        "print('Original Audio')\n",
        "play(audio)\n",
        "print('Resynthesized Audio')\n",
        "play(audio_gen)\n",
        "print('Filtered Noise Audio')\n",
        "audio_noise = controls['noise']['signal']\n",
        "play(audio_noise)\n",
        "\n",
        "specplot(audio)\n",
        "specplot(audio_gen)\n",
        "specplot(audio_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVhoLzV-ZYav"
      },
      "outputs": [],
      "source": [
        "batch_idx = 0\n",
        "get = lambda key: ddsp.core.nested_lookup(key, controls)[batch_idx]\n",
        "\n",
        "amps = get('harmonic/controls/amplitudes')\n",
        "harmonic_distribution = get('harmonic/controls/harmonic_distribution')\n",
        "noise_magnitudes = get('noise/controls/magnitudes')\n",
        "f0_hz = get('f0_hz')\n",
        "loudness = get('loudness_db')\n",
        "\n",
        "audio_noise = get('noise/signal')\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "f.suptitle('Input Features', fontsize=16)\n",
        "ax[0].plot(loudness)\n",
        "ax[0].set_ylabel('Loudness')\n",
        "ax[1].plot(f0_hz)\n",
        "ax[1].set_ylabel('F0_Hz')\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "f.suptitle('Synth Params', fontsize=16)\n",
        "ax[0].semilogy(amps)\n",
        "ax[0].set_ylabel('Amps')\n",
        "ax[0].set_ylim(1e-5, 2)\n",
        "# ax[0].semilogy(harmonic_distribution)\n",
        "ax[1].matshow(np.rot90(np.log10(harmonic_distribution + 1e-6)),\n",
        "              cmap=plt.cm.magma, \n",
        "              aspect='auto')\n",
        "ax[1].set_ylabel('Harmonic Distribution')\n",
        "ax[1].set_xticks([])\n",
        "_ = ax[1].set_yticks([])\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
        "# f.suptitle('Filtered Noise Params', fontsize=16)\n",
        "ax.matshow(np.rot90(np.log10(noise_magnitudes + 1e-6)), \n",
        "           cmap=plt.cm.magma, \n",
        "           aspect='auto')\n",
        "ax.set_ylabel('Filtered Noise Magnitudes')\n",
        "ax.set_xticks([])\n",
        "_ = ax.set_yticks([])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hMqWDc_m6rUC",
        "ZFIqwYGbZ-df",
        "khYj8yiMDxGL",
        "acGO0ifg0I3k",
        "Op0V8onI0VUK",
        "EWZQXFLehCU0",
        "uAZgDMV9hGyp",
        "MnnxpYbRrPrp",
        "IGvCE5BbrWTU",
        "RFEqt6e1DsqG",
        "2cj220vSF8_Y"
      ],
      "name": "3_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}